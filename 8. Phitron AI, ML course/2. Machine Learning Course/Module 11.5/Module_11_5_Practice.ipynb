{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "28d0c8ca",
      "metadata": {
        "id": "28d0c8ca"
      },
      "source": [
        "# Module 11.5 – Practice Problems on Decision Trees\n",
        "\n",
        "This notebook contains a small set of practice exercises based on Module 11:\n",
        "\n",
        "- Structure and intuition of decision trees  \n",
        "- Entropy / Gini and splits  \n",
        "- Pruning and overfitting  \n",
        "- Evaluation metrics (accuracy, precision, recall, F1)  \n",
        "- ROC curve, AUC, and threshold interpretation  \n",
        "\n",
        "Work through the questions in order. You can run the starter code, then **fill in the TODO parts**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8098ac9e",
      "metadata": {
        "id": "8098ac9e"
      },
      "source": [
        "## Problem 1 – Interpreting a Simple Decision Tree (Conceptual)\n",
        "\n",
        "Consider the following tiny dataset:\n",
        "\n",
        "| Weather | Windy | Play |\n",
        "|---------|-------|------|\n",
        "| Sunny   | No    | Yes  |\n",
        "| Sunny   | Yes   | Yes  |\n",
        "| Rainy   | No    | No   |\n",
        "| Rainy   | Yes   | No   |\n",
        "\n",
        "1. If we encode `Sunny = 1`, `Rainy = 0`, `Windy: No = 0, Yes = 1`, and train a decision tree on `Weather` and `Windy`, which **single split** do you expect the tree to choose first? Explain in 2–3 sentences.\n",
        "2. In your own words, explain what **Gini = 0** means for a node of a decision tree.\n",
        "3. Give a real-life example (outside cricket) where a single yes/no question is enough to make a perfect decision."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bce3359e",
      "metadata": {
        "id": "bce3359e"
      },
      "source": [
        "## Problem 2 – Build and Visualize a Simple Decision Tree\n",
        "\n",
        "In this exercise you will:\n",
        "\n",
        "- Create a tiny synthetic dataset (same as above, but in code)  \n",
        "- Train a `DecisionTreeClassifier`  \n",
        "- Visualize the tree and interpret it\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0b71902",
      "metadata": {
        "id": "a0b71902"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Create the synthetic dataset\n",
        "data = {\n",
        "    'Weather': ['Sunny','Rainy','Sunny','Sunny','Rainy','Rainy','Sunny','Rainy'],\n",
        "    'Windy':   [0,1,0,1,0,1,0,1],\n",
        "    'Play':    [1,0,1,1,0,0,1,0]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13bfafb5",
      "metadata": {
        "id": "13bfafb5"
      },
      "outputs": [],
      "source": [
        "# 2. Encode Weather as a numeric feature\n",
        "df['Weather_num'] = df['Weather'].map({'Sunny': 1, 'Rainy': 0})\n",
        "\n",
        "X = df[['Weather_num', 'Windy']]\n",
        "y = df['Play']\n",
        "\n",
        "# TODO: create and fit a DecisionTreeClassifier with max_depth=2\n",
        "\n",
        "# 3. Visualize the tree\n",
        "plt.figure(figsize=(8,4))\n",
        "plot_tree(model, feature_names=X.columns, class_names=['No','Yes'], filled=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64f654c6",
      "metadata": {
        "id": "64f654c6"
      },
      "source": [
        "**Your task:**\n",
        "\n",
        "1. Run the cells above.  \n",
        "2. In **2–4 sentences below**, describe how the tree is making the decision. Mention what the root split is and what each leaf predicts."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74044f29",
      "metadata": {
        "id": "74044f29"
      },
      "source": [
        "→ *Write your explanation here.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89d10c71",
      "metadata": {
        "id": "89d10c71"
      },
      "source": [
        "## Problem 3 – Decision Tree on a Heart-like Dataset\n",
        "\n",
        "We will now create a small synthetic dataset that looks a bit like a heart-disease dataset (with `age`, `chol`, `thalach`, and a binary `target`).\n",
        "\n",
        "Your tasks:\n",
        "\n",
        "1. Train a decision tree classifier.  \n",
        "2. Compute **accuracy, precision, recall, and F1-score**.  \n",
        "3. Change `max_depth` and observe how the metrics change.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f27fb0f",
      "metadata": {
        "id": "6f27fb0f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "np.random.seed(42)\n",
        "n_samples = 300\n",
        "\n",
        "age = np.random.randint(30, 80, size=n_samples)\n",
        "chol = np.random.randint(150, 300, size=n_samples)\n",
        "thalach = np.random.randint(90, 200, size=n_samples)\n",
        "\n",
        "# Simple synthetic risk score\n",
        "risk_score = 0.03 * (age - 40) + 0.02 * (chol - 200) - 0.02 * (thalach - 140)\n",
        "prob = 1 / (1 + np.exp(-0.05 * risk_score))\n",
        "target = (prob > np.median(prob)).astype(int)\n",
        "\n",
        "df_heart = pd.DataFrame({\n",
        "    'age': age,\n",
        "    'chol': chol,\n",
        "    'thalach': thalach,\n",
        "    'target': target\n",
        "})\n",
        "\n",
        "df_heart.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58ad55f8",
      "metadata": {
        "id": "58ad55f8"
      },
      "outputs": [],
      "source": [
        "# 1. Train-test split\n",
        "X = df_heart[['age','chol','thalach']]\n",
        "y = df_heart['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# TODO: create a DecisionTreeClassifier with max_depth=4 and fit it and predict\n",
        "\n",
        "\n",
        "# 2. Compute metrics\n",
        "print('Accuracy :', accuracy_score(y_test, y_pred))\n",
        "print('Precision:', precision_score(y_test, y_pred))\n",
        "print('Recall   :', recall_score(y_test, y_pred))\n",
        "print('F1-score :', f1_score(y_test, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d183944",
      "metadata": {
        "id": "9d183944"
      },
      "source": [
        "**Your task:**\n",
        "\n",
        "1. Change `max_depth` to different values (for example: 2, 3, 5, `None`) and re-run the cell.  \n",
        "2. Observe how accuracy, precision, recall, and F1-score change.  \n",
        "3. In 3–5 sentences, comment on which `max_depth` seems like a good trade-off between performance and overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f4c48d8",
      "metadata": {
        "id": "8f4c48d8"
      },
      "source": [
        "→ *Write your observations here.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "848146c8",
      "metadata": {
        "id": "848146c8"
      },
      "source": [
        "## Problem 4 – ROC Curve, AUC, and Thresholds\n",
        "\n",
        "In this final exercise you will:\n",
        "\n",
        "- Use the trained heart-disease tree from Problem 3  \n",
        "- Plot the ROC curve and compute AUC  \n",
        "- Try different decision thresholds and see how the confusion matrix changes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9083fcfb",
      "metadata": {
        "id": "9083fcfb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Get predicted probabilities for class 1\n",
        "y_proba = tree_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# TODO: 2. Compute ROC curve\n",
        "\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f}')\n",
        "plt.plot([0,1],[0,1],'--', label='Random model')\n",
        "plt.xlabel('False Positive Rate (FPR)')\n",
        "plt.ylabel('True Positive Rate (TPR / Recall)')\n",
        "plt.title('ROC Curve for Heart-like Decision Tree')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f3a5422",
      "metadata": {
        "id": "3f3a5422"
      },
      "outputs": [],
      "source": [
        "# 3. Play with different thresholds\n",
        "import numpy as np\n",
        "\n",
        "for thr in [0.3, 0.5, 0.7]:\n",
        "    y_custom = (y_proba >= thr).astype(int)\n",
        "    cm_thr = confusion_matrix(y_test, y_custom)\n",
        "    print(f'\\nThreshold = {thr}')\n",
        "    print(cm_thr)\n",
        "    print('Recall   :', recall_score(y_test, y_custom))\n",
        "    print('Precision:', precision_score(y_test, y_custom))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f41d468",
      "metadata": {
        "id": "5f41d468"
      },
      "source": [
        "**Your task:**\n",
        "\n",
        "1. Look at how the confusion matrices change as the threshold goes from 0.3 → 0.5 → 0.7.  \n",
        "2. Which threshold catches the most positive cases (highest recall)?  \n",
        "3. Which threshold gives the cleanest positive predictions (highest precision)?  \n",
        "4. If this model were used to screen for a serious heart condition, which threshold would you prefer, and why?\n",
        "\n",
        "→ *Write your explanation below in 4–6 sentences.*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}